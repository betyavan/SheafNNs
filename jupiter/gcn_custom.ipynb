{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9432d13c-f150-439a-b68b-02312405e83a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install tensorboard\n",
    "# !pip install pytorch-lightning\n",
    "# !pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80c057e9-38c1-4310-a50c-13c1e2e3bfb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from pygcn.utils import load_data, accuracy\n",
    "from pygcn.models import GCN\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c5d6513-a5d7-4c63-8b04-75115f7acad4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.mps.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3fa93ed-f7d1-467e-b1b2-3437b7874696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CORA_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        super(CORA_Dataset).__init__()\n",
    "        self.data = Planetoid(root='./cora/', name='cora')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[0]\n",
    "    \n",
    "dataset = CORA_Dataset()\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af00924c-2b28-4ca1-81a0-f99f395bb724",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class CORA_Dataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, adj, features, labels, idx_train, idx_val, idx_test):\n",
    "#         super(CORA_Dataset).__init__()\n",
    "#         self.adj = adj\n",
    "#         self.features = features\n",
    "#         self.labels = labels\n",
    "#         self.idx_train = idx_train\n",
    "#         self.idx_val = idx_val\n",
    "#         self.idx_test = idx_test\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return 1\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.adj, self.features, self.labels, self.idx_train, self.idx_val, self.idx_test\n",
    "    \n",
    "# dataset = CORA_Dataset(*load_data('pygcn/data/cora/'))\n",
    "# dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2444dd60-997e-41d6-bc51-1d727c954069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nfeat = dataset.data.x.size()[1]\n",
    "hidden = 16\n",
    "nclass = dataset.data.y.max().item() + 1\n",
    "dropout = 0.5\n",
    "laplac_size = dataset.data.edge_index.size(1)\n",
    "\n",
    "weight_decay = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79a1bcef-8f52-41dc-94a9-36e32c9b9446",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GCN_module(pl.LightningModule):\n",
    "    def __init__(self, learning_rate=0.01):\n",
    "        super(GCN_module, self).__init__()\n",
    "        self.model = GCN(nfeat=nfeat,\n",
    "                         nhid=hidden,\n",
    "                         nclass=nclass,\n",
    "                         dropout=dropout,\n",
    "                         laplac_size=laplac_size)\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss_fn = F.nll_loss\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.Adam(self.parameters(), lr=self.learning_rate,\n",
    "                           weight_decay=weight_decay)\n",
    "        return optim\n",
    "    \n",
    "    def forward(self, features, adj):\n",
    "        return self.model(features, adj)\n",
    "    \n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        data = train_batch\n",
    "        output = self.model(data.x, data.edge_index)\n",
    "        \n",
    "        labels = data.y\n",
    "        \n",
    "        loss_train = self.loss_fn(output[data.train_mask], labels[data.train_mask])\n",
    "        acc_train = accuracy(output[data.train_mask], labels[data.train_mask])\n",
    "        \n",
    "        loss_val = self.loss_fn(output[data.val_mask], labels[data.val_mask])\n",
    "        acc_val = accuracy(output[data.val_mask], labels[data.val_mask])\n",
    "        \n",
    "        self.log(\"loss_train\", loss_train, prog_bar=True)\n",
    "        self.log(\"acc_train\", acc_train, prog_bar=True)\n",
    "        \n",
    "        self.log(\"loss_val\", loss_val, prog_bar=True)\n",
    "        self.log(\"acc_val\", acc_val, prog_bar=True)\n",
    "        \n",
    "        return loss_train\n",
    "        \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1320acc-a71f-4b95-b3ab-5a7ec437c390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm -r lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "239a3fd7-b191-483b-a4a7-e5beef7f8865",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/i.betev/anaconda3/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    }
   ],
   "source": [
    "# checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor=\"acc_val\", mode=\"max\")\n",
    "\n",
    "device = \"cpu\"\n",
    "trainer = pl.Trainer(max_epochs=400, accelerator=device)#, callbacks=checkpoint_callback, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99679f6e-3b05-4499-9f2f-d7a2516d888b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "module = GCN_module()\n",
    "\n",
    "trainer.fit(module, dataloader, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2695b1-50ad-4734-823b-b454f0fcf663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56abc7e-b6fb-4d31-be9d-0c11436a8c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2901f195-2182-48de-90b4-1623dc099078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f16e4e-e571-416b-a005-01ef36c5bfec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d836d5e-b5fe-4515-9d7f-b34bf14577aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888ed1dc-5351-42a2-a930-499f6c6524fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cbf60b-02e9-430a-a92a-fbe048bfd4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a03723-e5b3-4454-af90-7ef6d3ead60d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7e6910a-677d-4f80-9050-f37ac24f3f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e905182-5e0f-49f8-897a-e5ef6bd16ddd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45446790-efdc-4d5f-a8f7-2bb4dec53310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n"
     ]
    }
   ],
   "source": [
    "adj, features, labels, idx_train, idx_val, idx_test = load_data('pygcn/data/cora/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "725648ee-ef5a-456e-9d8b-9bb2d2aaa88d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hidden = 16\n",
    "dropout = 0.5\n",
    "lr = 0.01\n",
    "weight_decay = 5e-4\n",
    "device = \"cpu\"\n",
    "\n",
    "model = GCN(nfeat=features.shape[1],\n",
    "            nhid=hidden,\n",
    "            nclass=labels.max().item() + 1,\n",
    "            dropout=dropout)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "model.to(device)\n",
    "features = features.to(device)\n",
    "adj = adj.to(device)\n",
    "labels = labels.to(device)\n",
    "idx_train = idx_train.to(device)\n",
    "idx_val = idx_val.to(device)\n",
    "idx_test = idx_test.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b408014-0ef5-4b24-ace5-3f5529b7474e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(features, adj)\n",
    "    loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
    "    # log\n",
    "    # writer.add_scalar(\"Loss/train\", loss_train, epoch)\n",
    "    acc_train = accuracy(output[idx_train], labels[idx_train])\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # if not args.fastmode:\n",
    "    #     # Evaluate validation set performance separately,\n",
    "    #     # deactivates dropout during validation run.\n",
    "    #     model.eval()\n",
    "    #     output = model(features, adj)\n",
    "\n",
    "    loss_val = F.nll_loss(output[idx_val], labels[idx_val])\n",
    "    acc_val = accuracy(output[idx_val], labels[idx_val])\n",
    "    print('Epoch: {:04d}'.format(epoch+1),\n",
    "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "          'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "          'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "          'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    output = model(features, adj)\n",
    "    loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
    "    acc_test = accuracy(output[idx_test], labels[idx_test])\n",
    "    print(\"Test set results:\",\n",
    "          \"loss= {:.4f}\".format(loss_test.item()),\n",
    "          \"accuracy= {:.4f}\".format(acc_test.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b364f52-6e9a-4821-b7c7-19635d989741",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 2.0034 acc_train: 0.1214 loss_val: 2.0204 acc_val: 0.1133 time: 0.0047s\n",
      "Epoch: 0002 loss_train: 1.9814 acc_train: 0.1214 loss_val: 2.0026 acc_val: 0.1133 time: 0.0029s\n",
      "Epoch: 0003 loss_train: 1.9625 acc_train: 0.1429 loss_val: 1.9839 acc_val: 0.1200 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 1.9549 acc_train: 0.1857 loss_val: 1.9724 acc_val: 0.1333 time: 0.0030s\n",
      "Epoch: 0005 loss_train: 1.9371 acc_train: 0.2357 loss_val: 1.9581 acc_val: 0.1533 time: 0.0029s\n",
      "Epoch: 0006 loss_train: 1.9290 acc_train: 0.2357 loss_val: 1.9486 acc_val: 0.1667 time: 0.0031s\n",
      "Epoch: 0007 loss_train: 1.9130 acc_train: 0.2357 loss_val: 1.9350 acc_val: 0.1633 time: 0.0029s\n",
      "Epoch: 0008 loss_train: 1.9043 acc_train: 0.2286 loss_val: 1.9261 acc_val: 0.1633 time: 0.0030s\n",
      "Epoch: 0009 loss_train: 1.8993 acc_train: 0.2286 loss_val: 1.9165 acc_val: 0.1600 time: 0.0026s\n",
      "Epoch: 0010 loss_train: 1.8824 acc_train: 0.2286 loss_val: 1.9033 acc_val: 0.1700 time: 0.0027s\n",
      "Epoch: 0011 loss_train: 1.8801 acc_train: 0.2143 loss_val: 1.8964 acc_val: 0.1567 time: 0.0027s\n",
      "Epoch: 0012 loss_train: 1.8685 acc_train: 0.2357 loss_val: 1.8824 acc_val: 0.1967 time: 0.0026s\n",
      "Epoch: 0013 loss_train: 1.8600 acc_train: 0.2643 loss_val: 1.8828 acc_val: 0.1833 time: 0.0027s\n",
      "Epoch: 0014 loss_train: 1.8551 acc_train: 0.2500 loss_val: 1.8677 acc_val: 0.1900 time: 0.0026s\n",
      "Epoch: 0015 loss_train: 1.8347 acc_train: 0.3143 loss_val: 1.8556 acc_val: 0.2267 time: 0.0026s\n",
      "Epoch: 0016 loss_train: 1.8135 acc_train: 0.3429 loss_val: 1.8432 acc_val: 0.2833 time: 0.0026s\n",
      "Epoch: 0017 loss_train: 1.8011 acc_train: 0.4071 loss_val: 1.8337 acc_val: 0.3467 time: 0.0027s\n",
      "Epoch: 0018 loss_train: 1.8003 acc_train: 0.4214 loss_val: 1.8199 acc_val: 0.3600 time: 0.0025s\n",
      "Epoch: 0019 loss_train: 1.7902 acc_train: 0.3571 loss_val: 1.8096 acc_val: 0.3067 time: 0.0026s\n",
      "Epoch: 0020 loss_train: 1.7776 acc_train: 0.4071 loss_val: 1.7887 acc_val: 0.3467 time: 0.0027s\n",
      "Epoch: 0021 loss_train: 1.7859 acc_train: 0.3357 loss_val: 1.7973 acc_val: 0.3433 time: 0.0026s\n",
      "Epoch: 0022 loss_train: 1.7474 acc_train: 0.3786 loss_val: 1.7811 acc_val: 0.3400 time: 0.0025s\n",
      "Epoch: 0023 loss_train: 1.7344 acc_train: 0.3643 loss_val: 1.7540 acc_val: 0.3667 time: 0.0025s\n",
      "Epoch: 0024 loss_train: 1.7583 acc_train: 0.3214 loss_val: 1.7769 acc_val: 0.3400 time: 0.0024s\n",
      "Epoch: 0025 loss_train: 1.7193 acc_train: 0.3786 loss_val: 1.7413 acc_val: 0.3400 time: 0.0027s\n",
      "Epoch: 0026 loss_train: 1.7127 acc_train: 0.3357 loss_val: 1.7533 acc_val: 0.3267 time: 0.0025s\n",
      "Epoch: 0027 loss_train: 1.7121 acc_train: 0.3429 loss_val: 1.7245 acc_val: 0.3400 time: 0.0024s\n",
      "Epoch: 0028 loss_train: 1.6964 acc_train: 0.3214 loss_val: 1.7137 acc_val: 0.3567 time: 0.0024s\n",
      "Epoch: 0029 loss_train: 1.6462 acc_train: 0.3357 loss_val: 1.6965 acc_val: 0.3533 time: 0.0027s\n",
      "Epoch: 0030 loss_train: 1.6644 acc_train: 0.3571 loss_val: 1.7033 acc_val: 0.3600 time: 0.0023s\n",
      "Epoch: 0031 loss_train: 1.6793 acc_train: 0.3429 loss_val: 1.7114 acc_val: 0.3333 time: 0.0025s\n",
      "Epoch: 0032 loss_train: 1.6640 acc_train: 0.3500 loss_val: 1.6831 acc_val: 0.3533 time: 0.0026s\n",
      "Epoch: 0033 loss_train: 1.6309 acc_train: 0.3929 loss_val: 1.6728 acc_val: 0.3733 time: 0.0027s\n",
      "Epoch: 0034 loss_train: 1.6308 acc_train: 0.3500 loss_val: 1.6652 acc_val: 0.3600 time: 0.0025s\n",
      "Epoch: 0035 loss_train: 1.6048 acc_train: 0.3571 loss_val: 1.6517 acc_val: 0.3667 time: 0.0026s\n",
      "Epoch: 0036 loss_train: 1.6185 acc_train: 0.3429 loss_val: 1.6819 acc_val: 0.3867 time: 0.0027s\n",
      "Epoch: 0037 loss_train: 1.5906 acc_train: 0.3929 loss_val: 1.6627 acc_val: 0.3633 time: 0.0026s\n",
      "Epoch: 0038 loss_train: 1.5775 acc_train: 0.3857 loss_val: 1.6539 acc_val: 0.3567 time: 0.0025s\n",
      "Epoch: 0039 loss_train: 1.5823 acc_train: 0.3929 loss_val: 1.6466 acc_val: 0.3833 time: 0.0028s\n",
      "Epoch: 0040 loss_train: 1.5584 acc_train: 0.4286 loss_val: 1.6471 acc_val: 0.4133 time: 0.0027s\n",
      "Epoch: 0041 loss_train: 1.5957 acc_train: 0.4214 loss_val: 1.6390 acc_val: 0.3933 time: 0.0025s\n",
      "Epoch: 0042 loss_train: 1.5249 acc_train: 0.4143 loss_val: 1.6101 acc_val: 0.4233 time: 0.0025s\n",
      "Epoch: 0043 loss_train: 1.5082 acc_train: 0.4571 loss_val: 1.6081 acc_val: 0.4200 time: 0.0029s\n",
      "Epoch: 0044 loss_train: 1.5134 acc_train: 0.4857 loss_val: 1.5857 acc_val: 0.4300 time: 0.0026s\n",
      "Epoch: 0045 loss_train: 1.4845 acc_train: 0.5286 loss_val: 1.5600 acc_val: 0.5233 time: 0.0026s\n",
      "Epoch: 0046 loss_train: 1.4588 acc_train: 0.5286 loss_val: 1.5566 acc_val: 0.4867 time: 0.0025s\n",
      "Epoch: 0047 loss_train: 1.4535 acc_train: 0.5357 loss_val: 1.5706 acc_val: 0.4700 time: 0.0025s\n",
      "Epoch: 0048 loss_train: 1.4560 acc_train: 0.5429 loss_val: 1.5548 acc_val: 0.4667 time: 0.0025s\n",
      "Epoch: 0049 loss_train: 1.4220 acc_train: 0.5571 loss_val: 1.5499 acc_val: 0.4367 time: 0.0027s\n",
      "Epoch: 0050 loss_train: 1.4152 acc_train: 0.5500 loss_val: 1.5205 acc_val: 0.5200 time: 0.0025s\n",
      "Epoch: 0051 loss_train: 1.4217 acc_train: 0.5714 loss_val: 1.5309 acc_val: 0.5100 time: 0.0025s\n",
      "Epoch: 0052 loss_train: 1.3585 acc_train: 0.6071 loss_val: 1.4825 acc_val: 0.5600 time: 0.0025s\n",
      "Epoch: 0053 loss_train: 1.3266 acc_train: 0.6000 loss_val: 1.4703 acc_val: 0.5333 time: 0.0024s\n",
      "Epoch: 0054 loss_train: 1.3385 acc_train: 0.6357 loss_val: 1.4806 acc_val: 0.5500 time: 0.0027s\n",
      "Epoch: 0055 loss_train: 1.3323 acc_train: 0.6429 loss_val: 1.4763 acc_val: 0.5867 time: 0.0027s\n",
      "Epoch: 0056 loss_train: 1.2978 acc_train: 0.6286 loss_val: 1.4584 acc_val: 0.5367 time: 0.0026s\n",
      "Epoch: 0057 loss_train: 1.2657 acc_train: 0.6786 loss_val: 1.4156 acc_val: 0.5700 time: 0.0025s\n",
      "Epoch: 0058 loss_train: 1.2836 acc_train: 0.6714 loss_val: 1.4478 acc_val: 0.5767 time: 0.0027s\n",
      "Epoch: 0059 loss_train: 1.2404 acc_train: 0.6714 loss_val: 1.3900 acc_val: 0.5900 time: 0.0027s\n",
      "Epoch: 0060 loss_train: 1.2293 acc_train: 0.6857 loss_val: 1.4026 acc_val: 0.6133 time: 0.0026s\n",
      "Epoch: 0061 loss_train: 1.1901 acc_train: 0.6857 loss_val: 1.3864 acc_val: 0.5767 time: 0.0026s\n",
      "Epoch: 0062 loss_train: 1.1973 acc_train: 0.6857 loss_val: 1.3948 acc_val: 0.5733 time: 0.0025s\n",
      "Epoch: 0063 loss_train: 1.1722 acc_train: 0.6929 loss_val: 1.3711 acc_val: 0.5933 time: 0.0024s\n",
      "Epoch: 0064 loss_train: 1.1238 acc_train: 0.7071 loss_val: 1.3205 acc_val: 0.6100 time: 0.0026s\n",
      "Epoch: 0065 loss_train: 1.1403 acc_train: 0.6929 loss_val: 1.3270 acc_val: 0.5933 time: 0.0024s\n",
      "Epoch: 0066 loss_train: 1.1124 acc_train: 0.7643 loss_val: 1.3391 acc_val: 0.6167 time: 0.0024s\n",
      "Epoch: 0067 loss_train: 1.1219 acc_train: 0.7714 loss_val: 1.3125 acc_val: 0.6300 time: 0.0025s\n",
      "Epoch: 0068 loss_train: 1.1055 acc_train: 0.7357 loss_val: 1.3033 acc_val: 0.6067 time: 0.0024s\n",
      "Epoch: 0069 loss_train: 1.0349 acc_train: 0.7357 loss_val: 1.2878 acc_val: 0.6333 time: 0.0024s\n",
      "Epoch: 0070 loss_train: 1.0419 acc_train: 0.7643 loss_val: 1.2831 acc_val: 0.6333 time: 0.0025s\n",
      "Epoch: 0071 loss_train: 1.0349 acc_train: 0.7571 loss_val: 1.2589 acc_val: 0.6400 time: 0.0025s\n",
      "Epoch: 0072 loss_train: 1.0302 acc_train: 0.8214 loss_val: 1.2544 acc_val: 0.6500 time: 0.0025s\n",
      "Epoch: 0073 loss_train: 1.0243 acc_train: 0.7571 loss_val: 1.2476 acc_val: 0.7033 time: 0.0025s\n",
      "Epoch: 0074 loss_train: 1.0147 acc_train: 0.8071 loss_val: 1.2527 acc_val: 0.5933 time: 0.0027s\n",
      "Epoch: 0075 loss_train: 0.9595 acc_train: 0.8000 loss_val: 1.2128 acc_val: 0.6600 time: 0.0027s\n",
      "Epoch: 0076 loss_train: 0.9927 acc_train: 0.7571 loss_val: 1.2067 acc_val: 0.6600 time: 0.0025s\n",
      "Epoch: 0077 loss_train: 0.9453 acc_train: 0.8071 loss_val: 1.1600 acc_val: 0.6600 time: 0.0026s\n",
      "Epoch: 0078 loss_train: 0.9605 acc_train: 0.8000 loss_val: 1.1662 acc_val: 0.6767 time: 0.0028s\n",
      "Epoch: 0079 loss_train: 0.9595 acc_train: 0.8143 loss_val: 1.1954 acc_val: 0.6900 time: 0.0024s\n",
      "Epoch: 0080 loss_train: 0.9321 acc_train: 0.7929 loss_val: 1.1865 acc_val: 0.6700 time: 0.0027s\n",
      "Epoch: 0081 loss_train: 0.9136 acc_train: 0.8000 loss_val: 1.1543 acc_val: 0.6867 time: 0.0025s\n",
      "Epoch: 0082 loss_train: 0.8553 acc_train: 0.8143 loss_val: 1.1079 acc_val: 0.7033 time: 0.0028s\n",
      "Epoch: 0083 loss_train: 0.8659 acc_train: 0.8286 loss_val: 1.1257 acc_val: 0.7133 time: 0.0029s\n",
      "Epoch: 0084 loss_train: 0.9267 acc_train: 0.7714 loss_val: 1.1484 acc_val: 0.7100 time: 0.0034s\n",
      "Epoch: 0085 loss_train: 0.8339 acc_train: 0.8500 loss_val: 1.1281 acc_val: 0.6967 time: 0.0034s\n",
      "Epoch: 0086 loss_train: 0.8631 acc_train: 0.8357 loss_val: 1.1123 acc_val: 0.7133 time: 0.0027s\n",
      "Epoch: 0087 loss_train: 0.8771 acc_train: 0.8571 loss_val: 1.0931 acc_val: 0.7333 time: 0.0027s\n",
      "Epoch: 0088 loss_train: 0.7996 acc_train: 0.8357 loss_val: 1.0721 acc_val: 0.7167 time: 0.0032s\n",
      "Epoch: 0089 loss_train: 0.8232 acc_train: 0.8286 loss_val: 1.0801 acc_val: 0.7300 time: 0.0029s\n",
      "Epoch: 0090 loss_train: 0.7751 acc_train: 0.8786 loss_val: 1.0381 acc_val: 0.7467 time: 0.0028s\n",
      "Epoch: 0091 loss_train: 0.8101 acc_train: 0.8571 loss_val: 1.0387 acc_val: 0.7267 time: 0.0027s\n",
      "Epoch: 0092 loss_train: 0.8115 acc_train: 0.8714 loss_val: 1.0489 acc_val: 0.7367 time: 0.0027s\n",
      "Epoch: 0093 loss_train: 0.7682 acc_train: 0.8500 loss_val: 1.0776 acc_val: 0.7267 time: 0.0027s\n",
      "Epoch: 0094 loss_train: 0.7602 acc_train: 0.8500 loss_val: 1.0520 acc_val: 0.7267 time: 0.0025s\n",
      "Epoch: 0095 loss_train: 0.7841 acc_train: 0.8143 loss_val: 0.9673 acc_val: 0.7633 time: 0.0028s\n",
      "Epoch: 0096 loss_train: 0.7670 acc_train: 0.8500 loss_val: 1.0505 acc_val: 0.7233 time: 0.0026s\n",
      "Epoch: 0097 loss_train: 0.7295 acc_train: 0.8643 loss_val: 1.0035 acc_val: 0.7400 time: 0.0026s\n",
      "Epoch: 0098 loss_train: 0.7139 acc_train: 0.8929 loss_val: 1.0192 acc_val: 0.7133 time: 0.0027s\n",
      "Epoch: 0099 loss_train: 0.7654 acc_train: 0.8571 loss_val: 1.0529 acc_val: 0.7067 time: 0.0027s\n",
      "Epoch: 0100 loss_train: 0.7043 acc_train: 0.8714 loss_val: 0.9963 acc_val: 0.7567 time: 0.0027s\n",
      "Epoch: 0101 loss_train: 0.7187 acc_train: 0.8500 loss_val: 1.0361 acc_val: 0.7000 time: 0.0025s\n",
      "Epoch: 0102 loss_train: 0.7165 acc_train: 0.8857 loss_val: 1.0386 acc_val: 0.7233 time: 0.0025s\n",
      "Epoch: 0103 loss_train: 0.7297 acc_train: 0.8643 loss_val: 1.0280 acc_val: 0.7633 time: 0.0025s\n",
      "Epoch: 0104 loss_train: 0.6646 acc_train: 0.8857 loss_val: 0.9877 acc_val: 0.7400 time: 0.0028s\n",
      "Epoch: 0105 loss_train: 0.6965 acc_train: 0.8429 loss_val: 1.0111 acc_val: 0.7367 time: 0.0026s\n",
      "Epoch: 0106 loss_train: 0.6914 acc_train: 0.8643 loss_val: 0.9875 acc_val: 0.7367 time: 0.0026s\n",
      "Epoch: 0107 loss_train: 0.6366 acc_train: 0.8714 loss_val: 0.9630 acc_val: 0.7233 time: 0.0027s\n",
      "Epoch: 0108 loss_train: 0.7026 acc_train: 0.8286 loss_val: 0.9562 acc_val: 0.7500 time: 0.0028s\n",
      "Epoch: 0109 loss_train: 0.6623 acc_train: 0.8786 loss_val: 0.9937 acc_val: 0.7533 time: 0.0027s\n",
      "Epoch: 0110 loss_train: 0.6250 acc_train: 0.8786 loss_val: 0.9350 acc_val: 0.7533 time: 0.0027s\n",
      "Epoch: 0111 loss_train: 0.6261 acc_train: 0.8857 loss_val: 0.9310 acc_val: 0.7533 time: 0.0025s\n",
      "Epoch: 0112 loss_train: 0.6722 acc_train: 0.8714 loss_val: 0.9183 acc_val: 0.7733 time: 0.0023s\n",
      "Epoch: 0113 loss_train: 0.6305 acc_train: 0.8286 loss_val: 0.9687 acc_val: 0.7067 time: 0.0025s\n",
      "Epoch: 0114 loss_train: 0.6119 acc_train: 0.9071 loss_val: 0.9027 acc_val: 0.7667 time: 0.0027s\n",
      "Epoch: 0115 loss_train: 0.5770 acc_train: 0.9214 loss_val: 0.9240 acc_val: 0.7800 time: 0.0027s\n",
      "Epoch: 0116 loss_train: 0.5875 acc_train: 0.8786 loss_val: 0.9067 acc_val: 0.7567 time: 0.0025s\n",
      "Epoch: 0117 loss_train: 0.6241 acc_train: 0.8929 loss_val: 0.9048 acc_val: 0.7733 time: 0.0026s\n",
      "Epoch: 0118 loss_train: 0.6017 acc_train: 0.8786 loss_val: 0.9392 acc_val: 0.7500 time: 0.0026s\n",
      "Epoch: 0119 loss_train: 0.6188 acc_train: 0.8714 loss_val: 0.9322 acc_val: 0.7500 time: 0.0024s\n",
      "Epoch: 0120 loss_train: 0.6290 acc_train: 0.8857 loss_val: 0.8991 acc_val: 0.7667 time: 0.0025s\n",
      "Epoch: 0121 loss_train: 0.6118 acc_train: 0.9000 loss_val: 0.9456 acc_val: 0.7600 time: 0.0024s\n",
      "Epoch: 0122 loss_train: 0.5733 acc_train: 0.8929 loss_val: 0.8681 acc_val: 0.7733 time: 0.0026s\n",
      "Epoch: 0123 loss_train: 0.5893 acc_train: 0.8857 loss_val: 0.8986 acc_val: 0.7567 time: 0.0026s\n",
      "Epoch: 0124 loss_train: 0.5873 acc_train: 0.9214 loss_val: 0.8868 acc_val: 0.7633 time: 0.0025s\n",
      "Epoch: 0125 loss_train: 0.5568 acc_train: 0.8929 loss_val: 0.8957 acc_val: 0.7533 time: 0.0027s\n",
      "Epoch: 0126 loss_train: 0.5896 acc_train: 0.9071 loss_val: 0.8392 acc_val: 0.7900 time: 0.0026s\n",
      "Epoch: 0127 loss_train: 0.5540 acc_train: 0.9214 loss_val: 0.9224 acc_val: 0.7533 time: 0.0026s\n",
      "Epoch: 0128 loss_train: 0.5328 acc_train: 0.9357 loss_val: 0.8602 acc_val: 0.7733 time: 0.0025s\n",
      "Epoch: 0129 loss_train: 0.5500 acc_train: 0.9500 loss_val: 0.9170 acc_val: 0.7400 time: 0.0024s\n",
      "Epoch: 0130 loss_train: 0.5635 acc_train: 0.9214 loss_val: 0.8875 acc_val: 0.7700 time: 0.0027s\n",
      "Epoch: 0131 loss_train: 0.5126 acc_train: 0.9357 loss_val: 0.8987 acc_val: 0.7667 time: 0.0025s\n",
      "Epoch: 0132 loss_train: 0.5347 acc_train: 0.9143 loss_val: 0.8669 acc_val: 0.7567 time: 0.0026s\n",
      "Epoch: 0133 loss_train: 0.5507 acc_train: 0.8857 loss_val: 0.8243 acc_val: 0.7767 time: 0.0025s\n",
      "Epoch: 0134 loss_train: 0.5207 acc_train: 0.9214 loss_val: 0.8623 acc_val: 0.7567 time: 0.0025s\n",
      "Epoch: 0135 loss_train: 0.5024 acc_train: 0.9214 loss_val: 0.8641 acc_val: 0.7567 time: 0.0026s\n",
      "Epoch: 0136 loss_train: 0.5608 acc_train: 0.8643 loss_val: 0.8429 acc_val: 0.7900 time: 0.0025s\n",
      "Epoch: 0137 loss_train: 0.5417 acc_train: 0.8929 loss_val: 0.8424 acc_val: 0.7667 time: 0.0027s\n",
      "Epoch: 0138 loss_train: 0.4887 acc_train: 0.9500 loss_val: 0.7954 acc_val: 0.7900 time: 0.0027s\n",
      "Epoch: 0139 loss_train: 0.5117 acc_train: 0.9214 loss_val: 0.8667 acc_val: 0.7833 time: 0.0026s\n",
      "Epoch: 0140 loss_train: 0.4773 acc_train: 0.9357 loss_val: 0.8347 acc_val: 0.7700 time: 0.0025s\n",
      "Epoch: 0141 loss_train: 0.4918 acc_train: 0.9214 loss_val: 0.8130 acc_val: 0.7900 time: 0.0028s\n",
      "Epoch: 0142 loss_train: 0.5027 acc_train: 0.9357 loss_val: 0.8081 acc_val: 0.8000 time: 0.0025s\n",
      "Epoch: 0143 loss_train: 0.4964 acc_train: 0.9357 loss_val: 0.8600 acc_val: 0.7767 time: 0.0025s\n",
      "Epoch: 0144 loss_train: 0.4987 acc_train: 0.9000 loss_val: 0.8477 acc_val: 0.7700 time: 0.0025s\n",
      "Epoch: 0145 loss_train: 0.4710 acc_train: 0.9429 loss_val: 0.8021 acc_val: 0.7900 time: 0.0024s\n",
      "Epoch: 0146 loss_train: 0.4904 acc_train: 0.9143 loss_val: 0.8102 acc_val: 0.7700 time: 0.0024s\n",
      "Epoch: 0147 loss_train: 0.4323 acc_train: 0.9643 loss_val: 0.8156 acc_val: 0.7733 time: 0.0027s\n",
      "Epoch: 0148 loss_train: 0.4840 acc_train: 0.9000 loss_val: 0.8576 acc_val: 0.7767 time: 0.0025s\n",
      "Epoch: 0149 loss_train: 0.4579 acc_train: 0.9429 loss_val: 0.8410 acc_val: 0.7667 time: 0.0025s\n",
      "Epoch: 0150 loss_train: 0.4338 acc_train: 0.9143 loss_val: 0.8045 acc_val: 0.7700 time: 0.0025s\n",
      "Epoch: 0151 loss_train: 0.4568 acc_train: 0.9714 loss_val: 0.7834 acc_val: 0.7800 time: 0.0025s\n",
      "Epoch: 0152 loss_train: 0.4509 acc_train: 0.9357 loss_val: 0.8361 acc_val: 0.7600 time: 0.0025s\n",
      "Epoch: 0153 loss_train: 0.4559 acc_train: 0.9357 loss_val: 0.8265 acc_val: 0.7667 time: 0.0026s\n",
      "Epoch: 0154 loss_train: 0.4685 acc_train: 0.9214 loss_val: 0.7931 acc_val: 0.7733 time: 0.0026s\n",
      "Epoch: 0155 loss_train: 0.4451 acc_train: 0.9286 loss_val: 0.8257 acc_val: 0.7667 time: 0.0026s\n",
      "Epoch: 0156 loss_train: 0.4668 acc_train: 0.9143 loss_val: 0.8098 acc_val: 0.7833 time: 0.0025s\n",
      "Epoch: 0157 loss_train: 0.4296 acc_train: 0.9714 loss_val: 0.8164 acc_val: 0.7700 time: 0.0024s\n",
      "Epoch: 0158 loss_train: 0.4182 acc_train: 0.9500 loss_val: 0.7773 acc_val: 0.7633 time: 0.0026s\n",
      "Epoch: 0159 loss_train: 0.4155 acc_train: 0.9571 loss_val: 0.7814 acc_val: 0.7867 time: 0.0027s\n",
      "Epoch: 0160 loss_train: 0.4057 acc_train: 0.9500 loss_val: 0.8016 acc_val: 0.7767 time: 0.0028s\n",
      "Epoch: 0161 loss_train: 0.4350 acc_train: 0.9643 loss_val: 0.8444 acc_val: 0.7700 time: 0.0030s\n",
      "Epoch: 0162 loss_train: 0.4311 acc_train: 0.9429 loss_val: 0.7987 acc_val: 0.7567 time: 0.0029s\n",
      "Epoch: 0163 loss_train: 0.4616 acc_train: 0.9357 loss_val: 0.8310 acc_val: 0.7700 time: 0.0026s\n",
      "Epoch: 0164 loss_train: 0.4290 acc_train: 0.9429 loss_val: 0.7726 acc_val: 0.7933 time: 0.0026s\n",
      "Epoch: 0165 loss_train: 0.4235 acc_train: 0.9429 loss_val: 0.7645 acc_val: 0.7767 time: 0.0030s\n",
      "Epoch: 0166 loss_train: 0.4465 acc_train: 0.9214 loss_val: 0.7820 acc_val: 0.7933 time: 0.0027s\n",
      "Epoch: 0167 loss_train: 0.4308 acc_train: 0.9286 loss_val: 0.7901 acc_val: 0.7567 time: 0.0026s\n",
      "Epoch: 0168 loss_train: 0.4190 acc_train: 0.9500 loss_val: 0.7908 acc_val: 0.7900 time: 0.0025s\n",
      "Epoch: 0169 loss_train: 0.4169 acc_train: 0.9214 loss_val: 0.8020 acc_val: 0.7700 time: 0.0028s\n",
      "Epoch: 0170 loss_train: 0.4348 acc_train: 0.9357 loss_val: 0.8170 acc_val: 0.7833 time: 0.0028s\n",
      "Epoch: 0171 loss_train: 0.4366 acc_train: 0.9286 loss_val: 0.7881 acc_val: 0.7600 time: 0.0027s\n",
      "Epoch: 0172 loss_train: 0.3912 acc_train: 0.9500 loss_val: 0.8020 acc_val: 0.7833 time: 0.0026s\n",
      "Epoch: 0173 loss_train: 0.4349 acc_train: 0.9500 loss_val: 0.7570 acc_val: 0.7833 time: 0.0026s\n",
      "Epoch: 0174 loss_train: 0.3845 acc_train: 0.9500 loss_val: 0.8083 acc_val: 0.7533 time: 0.0026s\n",
      "Epoch: 0175 loss_train: 0.4283 acc_train: 0.9143 loss_val: 0.7835 acc_val: 0.7933 time: 0.0025s\n",
      "Epoch: 0176 loss_train: 0.4077 acc_train: 0.9071 loss_val: 0.7769 acc_val: 0.7767 time: 0.0025s\n",
      "Epoch: 0177 loss_train: 0.3842 acc_train: 0.9500 loss_val: 0.7237 acc_val: 0.7867 time: 0.0025s\n",
      "Epoch: 0178 loss_train: 0.4174 acc_train: 0.9214 loss_val: 0.7930 acc_val: 0.7733 time: 0.0024s\n",
      "Epoch: 0179 loss_train: 0.4197 acc_train: 0.9643 loss_val: 0.8036 acc_val: 0.7767 time: 0.0027s\n",
      "Epoch: 0180 loss_train: 0.4076 acc_train: 0.9500 loss_val: 0.7901 acc_val: 0.7533 time: 0.0026s\n",
      "Epoch: 0181 loss_train: 0.4119 acc_train: 0.9429 loss_val: 0.8058 acc_val: 0.7533 time: 0.0026s\n",
      "Epoch: 0182 loss_train: 0.3707 acc_train: 0.9500 loss_val: 0.7700 acc_val: 0.7600 time: 0.0026s\n",
      "Epoch: 0183 loss_train: 0.3677 acc_train: 0.9429 loss_val: 0.7759 acc_val: 0.7867 time: 0.0027s\n",
      "Epoch: 0184 loss_train: 0.4336 acc_train: 0.8929 loss_val: 0.7951 acc_val: 0.7767 time: 0.0026s\n",
      "Epoch: 0185 loss_train: 0.3616 acc_train: 0.9429 loss_val: 0.7879 acc_val: 0.7667 time: 0.0026s\n",
      "Epoch: 0186 loss_train: 0.4168 acc_train: 0.9214 loss_val: 0.7621 acc_val: 0.7667 time: 0.0024s\n",
      "Epoch: 0187 loss_train: 0.4027 acc_train: 0.9357 loss_val: 0.8115 acc_val: 0.7700 time: 0.0024s\n",
      "Epoch: 0188 loss_train: 0.3975 acc_train: 0.9286 loss_val: 0.8032 acc_val: 0.7933 time: 0.0025s\n",
      "Epoch: 0189 loss_train: 0.3842 acc_train: 0.9429 loss_val: 0.8117 acc_val: 0.7600 time: 0.0027s\n",
      "Epoch: 0190 loss_train: 0.3719 acc_train: 0.9571 loss_val: 0.8133 acc_val: 0.7500 time: 0.0026s\n",
      "Epoch: 0191 loss_train: 0.4021 acc_train: 0.9429 loss_val: 0.7810 acc_val: 0.8033 time: 0.0024s\n",
      "Epoch: 0192 loss_train: 0.3717 acc_train: 0.9571 loss_val: 0.7932 acc_val: 0.7833 time: 0.0025s\n",
      "Epoch: 0193 loss_train: 0.3693 acc_train: 0.9571 loss_val: 0.7741 acc_val: 0.7933 time: 0.0025s\n",
      "Epoch: 0194 loss_train: 0.3828 acc_train: 0.9286 loss_val: 0.7385 acc_val: 0.7867 time: 0.0025s\n",
      "Epoch: 0195 loss_train: 0.3751 acc_train: 0.9286 loss_val: 0.7653 acc_val: 0.7733 time: 0.0027s\n",
      "Epoch: 0196 loss_train: 0.3538 acc_train: 0.9714 loss_val: 0.7990 acc_val: 0.7600 time: 0.0025s\n",
      "Epoch: 0197 loss_train: 0.3668 acc_train: 0.9643 loss_val: 0.7854 acc_val: 0.7633 time: 0.0024s\n",
      "Epoch: 0198 loss_train: 0.3785 acc_train: 0.9500 loss_val: 0.7851 acc_val: 0.7700 time: 0.0027s\n",
      "Epoch: 0199 loss_train: 0.4004 acc_train: 0.9429 loss_val: 0.7819 acc_val: 0.7300 time: 0.0025s\n",
      "Epoch: 0200 loss_train: 0.4100 acc_train: 0.9357 loss_val: 0.8215 acc_val: 0.7800 time: 0.0025s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 0.5289s\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "t_total = time.time()\n",
    "for epoch in range(epochs):\n",
    "    train(epoch)\n",
    "    \n",
    "writer.flush()\n",
    "\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5b3e335-e3c8-4a6c-ab3e-332aa2abbde7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b32a969e-0981-4ae5-b29c-75ceadcaab92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63cc4139-767a-4435-9a65-fd50019190a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set results: loss= 0.7108 accuracy= 0.8290\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed668cf-0a04-4f6c-a7e8-ec415f229a29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cdb4a3-91f5-46f7-997c-6e7990cc4e60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
