{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9432d13c-f150-439a-b68b-02312405e83a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !clear\n",
    "# !pip install pytorch-lightning\n",
    "# !pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80c057e9-38c1-4310-a50c-13c1e2e3bfb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from pygcn.utils import load_data, accuracy\n",
    "\n",
    "from pygcn.models import GCN\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c5d6513-a5d7-4c63-8b04-75115f7acad4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.mps.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a98ebf2-4a8c-4153-ab50-38d253aa5d9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "03f4cf48-1092-43f6-b79c-dccb8adfb570",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading datasets/Cora/cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "datasets/Cora/cora_v2.zip: 100%|██████████| 132k/132k [00:00<00:00, 1.45MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting file to datasets/Cora/cora_v2_d697a464\n",
      "Finished data loading and preprocessing.\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done saving data into cached files.\n"
     ]
    }
   ],
   "source": [
    "dataset = dgl.data.CoraGraphDataset(raw_dir=f'datasets/Cora/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4c969bd4-5b76-4f28-b29f-e788e20ed0cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c0bae57a-4f7e-40da-a149-af742c7af3f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   0,    0,    0,  ..., 2707, 2707, 2707]),\n",
       " tensor([ 633, 1862, 2582,  ...,  598, 1473, 2706]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edges() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bc9d72b7-7bf8-4d30-9d54-7a27268fbdf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MySampler(dgl.dataloading.Sampler):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def sample(self, g, indices):\n",
    "        return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a583f82e-a53b-4686-a34c-574fbdfaba28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/sheaf/lib/python3.11/site-packages/dgl/dataloading/dataloader.py:1149: DGLWarning: Dataloader CPU affinity opt is not enabled, consider switching it on (see enable_cpu_affinity() or CPU best practices for DGL [https://docs.dgl.ai/tutorials/cpu/cpu_best_practises.html])\n",
      "  dgl_warning(\n"
     ]
    }
   ],
   "source": [
    "dataloader = dgl.dataloading.DataLoader(g, torch.arange(3), MySampler(),\n",
    "                                        batch_size=128, shuffle=False, drop_last=False, num_workers=4)\n",
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "813a5803-87ee-4c30-a81b-c5ec11d787d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_mask tensor(140)\n",
      "val_mask tensor(500)\n",
      "test_mask tensor(1000)\n"
     ]
    }
   ],
   "source": [
    "for name in [\"train_mask\", \"val_mask\", \"test_mask\"]:\n",
    "    print(name, g.ndata[name].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "90fe37eb-7fdc-4cf5-bcb2-c955682ad5db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.ndata[\"feat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9307465b-87da-47fb-a7ee-e788f822f7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b3d218-0902-4ce6-9bd7-02be168171d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb374f4-0ba3-44bb-b772-ca78fb3af304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3fa93ed-f7d1-467e-b1b2-3437b7874696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CORA_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        super(CORA_Dataset).__init__()\n",
    "        # self.data = Planetoid(root='./cora/', name='cora')[0]\n",
    "        self.data = Planetoid(root='datasets/cora/', name='cora')[0]\n",
    "\n",
    "        # scaler = StandardScaler()\n",
    "        # self.data.x[self.data.train_mask] = torch.FloatTensor(scaler.fit_transform(self.data.x[self.data.train_mask]))\n",
    "        # self.data.x[self.data.val_mask] = torch.FloatTensor(scaler.transform(self.data.x[self.data.val_mask]))\n",
    "        # self.data.x[self.data.test_mask] = torch.FloatTensor(scaler.transform(self.data.x[self.data.test_mask]))\n",
    "\n",
    "        # self.data.x = self.data.x.to(torch.float32)\n",
    "        \n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 1\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.x, self.data.edge_index, self.data.y,\\\n",
    "               self.data.train_mask | self.data.val_mask, self.data.test_mask\n",
    "    \n",
    "dataset = CORA_Dataset()\n",
    "# dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b9a4ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96f0514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pygcn.datasets import SheafDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dec1e1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "dataset = SheafDataset(\"cora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7bdfc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.data[0].ndata['feat'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c8de564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'cumulative explained variance')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA().fit(X)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f90528b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "752"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = 0\n",
    "while S[d] < S[-1] * 0.95:\n",
    "    d += 1\n",
    "d + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9da8e40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7f48b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01b4ddbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[1252, 1433], edge_index=[2, 2555], y=[1252], train_mask=[1252], val_mask=[1252], test_mask=[1252], n_id=[1252], e_id=[2555], num_sampled_nodes=[3], num_sampled_edges=[2], input_id=[128], batch_size=128)\n"
     ]
    }
   ],
   "source": [
    "loader = NeighborLoader(\n",
    "    dataset.data,\n",
    "    # Sample 30 neighbors for each node for 2 iterations\n",
    "    num_neighbors=[10] * 2,\n",
    "    # Use a batch size of 128 for sampling training nodes\n",
    "    batch_size=128,\n",
    "    input_nodes=dataset.data.train_mask,\n",
    ")\n",
    "\n",
    "for i in loader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c262c187",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3923724551.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[15], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    i.\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffc2a03e-9d1d-4c76-88db-9d85ee333b73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m degree\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cdist\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import degree\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde221a5-abe2-4829-920f-5d6f123e08df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deg = degree(dataset.data.edge_index[1], dataset.data.x.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9174b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "num = 15\n",
    "cnt = np.array(Counter(deg.numpy().astype(int)).most_common(num))\n",
    "plt.bar(cnt[:, 0], cnt[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5be2bb1-17c9-44e8-b319-ee53e92ac1ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def kNN(x, i, local_nbhood, k):\n",
    "#     dists = cdist([x[i].numpy()], x)[0]\n",
    "#     dists[local_nbhood] = np.inf\n",
    "#     ind = dists.argsort()[:k]\n",
    "#     return torch.tensor(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03adfef-c43f-4ad4-a679-e402b2b00485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_sheaf_laplacian(dataset, d, is_self_loops=True):\n",
    "    x, edge_index, _, _, _ = dataset[0]\n",
    "\n",
    "    n = x.size(1)\n",
    "    \n",
    "    O_matrices = torch.empty(x.size(0), n, d)\n",
    "\n",
    "    dists = cdist(x, x)\n",
    "    \n",
    "    for i in tqdm(range(x.size(0))):\n",
    "        local_nbhood = k_hop_subgraph(i, 1, edge_index, relabel_nodes=False)[0]\n",
    "        if len(local_nbhood) != d:\n",
    "            dists_i = dists[i].copy()\n",
    "            if len(local_nbhood) < d:\n",
    "                dists_i[local_nbhood] = np.inf\n",
    "            else:\n",
    "                dists_i[~local_nbhood] = np.inf\n",
    "            ind = dists_i.argsort()[: d if len(local_nbhood) > d else d - local_nbhood.size(0)]\n",
    "            nearests = torch.tensor(ind)\n",
    "            if local_nbhood.size(0) < d:\n",
    "                local_nbhood = torch.concat([local_nbhood, nearests])\n",
    "            else:\n",
    "                local_nbhood = nearests\n",
    "            \n",
    "\n",
    "\n",
    "        # if len(local_nbhood) < d:\n",
    "        #     dists_i = dists[i].copy()\n",
    "        #     dists_i[local_nbhood] = np.inf\n",
    "        #     ind = dists_i.argsort()[:d - local_nbhood.size(0)]\n",
    "        #     nearests = torch.tensor(ind) # kNN(x, i, local_nbhood, k=d-len(local_nbhood))\n",
    "        #     local_nbhood = torch.concat([local_nbhood, nearests])\n",
    "        # elif len(local_nbhood) > d:\n",
    "        #     local_nbhood = local_nbhood[local_nbhood != i][:d]\n",
    "\n",
    "\n",
    "        # print(x[local_nbhood].size())\n",
    "        U, _, _ = np.linalg.svd(x[local_nbhood].T) \n",
    "        # print(U.shape)\n",
    "        O_matrices[i] = torch.from_numpy(U[:, :d]) # n x d\n",
    "        \n",
    "    sheaf_laplacian = torch.empty(edge_index.size(1), n, n)\n",
    "        \n",
    "    for k in tqdm(range(edge_index.size(1))):\n",
    "        i, j = edge_index[:, k]\n",
    "        mul = torch.matmul(O_matrices[i], O_matrices[j].T) # n x n\n",
    "        U, _, V_T = np.linalg.svd(mul)\n",
    "        sheaf_laplacian[k] = torch.tensor(np.dot(U, V_T))\n",
    "        \n",
    "    if is_self_loops:\n",
    "        self_laplac = torch.concat([torch.eye(n).unsqueeze(0) for _ in range(x.size(0))])\n",
    "        sheaf_laplacian = torch.concat([sheaf_laplacian, self_laplac], axis=0)\n",
    "        \n",
    "    return sheaf_laplacian\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2444dd60-997e-41d6-bc51-1d727c954069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nfeat = dataset.data.x.size(1)\n",
    "hidden = 16 #16\n",
    "nclass = dataset.data.y.max().item() + 1\n",
    "dropout = 0.5\n",
    "# sheaf_laplacian = build_sheaf_laplacian(dataset, hidden).to(torch.float32)\n",
    "\n",
    "weight_decay = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3010af17-3d85-4081-8f7e-eb7b61428b81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(sheaf_laplacian, f'weights/sheaf_laplacian_cora_{hidden}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b64fa1-e818-4db7-a395-5004a78cee40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sheaf_laplacian = torch.load('sheaf_laplacian.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da8f3637",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79a1bcef-8f52-41dc-94a9-36e32c9b9446",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GCN_module(pl.LightningModule):\n",
    "    def __init__(self, learning_rate=0.01):\n",
    "        super(GCN_module, self).__init__()\n",
    "        self.model = GCN(nfeat=nfeat,\n",
    "                         nhid=hidden,\n",
    "                         nclass=nclass,\n",
    "                         dropout=dropout,\n",
    "                         sheaf_laplacian=None)\n",
    "        self.model.to(device)\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss_fn = F.nll_loss\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.Adam(self.parameters(), lr=self.learning_rate,\n",
    "                           weight_decay=weight_decay)\n",
    "        return optim\n",
    "    \n",
    "    def forward(self, features, adj):\n",
    "        return self.model(features, adj)\n",
    "    \n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        print(train_batch)\n",
    "        x, edge_index, y, train_mask, val_mask = train_batch\n",
    "        x, edge_index, y = x[0], edge_index[0], y[0]\n",
    "        train_mask, val_mask = train_mask[0], val_mask[0]\n",
    "        \n",
    "        output = self.model(x, edge_index)\n",
    "        \n",
    "        loss_train = self.loss_fn(output[train_mask], y[train_mask])\n",
    "        acc_train = accuracy(output[train_mask], y[train_mask])\n",
    "        \n",
    "        loss_val = self.loss_fn(output[val_mask], y[val_mask])\n",
    "        acc_val = accuracy(output[val_mask], y[val_mask])\n",
    "        \n",
    "        self.log(\"loss_train\", loss_train, prog_bar=True)\n",
    "        self.log(\"acc_train\", acc_train, prog_bar=True)\n",
    "        \n",
    "        self.log(\"loss_val\", loss_val, prog_bar=True)\n",
    "        self.log(\"acc_val\", acc_val, prog_bar=True)\n",
    "        \n",
    "        return loss_train\n",
    "        \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1320acc-a71f-4b95-b3ab-5a7ec437c390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm -r lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "239a3fd7-b191-483b-a4a7-e5beef7f8865",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor=\"acc_val\", mode=\"max\")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=400, accelerator=device)#, callbacks=checkpoint_callback, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99679f6e-3b05-4499-9f2f-d7a2516d888b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | GCN  | 10.0 K\n",
      "-------------------------------\n",
      "10.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "10.0 K    Total params\n",
      "0.040     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s]                               Data(x=[1239, 1433], edge_index=[2, 2542], y=[1239], train_mask=[1239], val_mask=[1239], test_mask=[1239], n_id=[1239], e_id=[2542], num_sampled_nodes=[3], num_sampled_edges=[2], input_id=[128], batch_size=128)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m module \u001b[38;5;241m=\u001b[39m GCN_module()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:987\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 987\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    992\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1033\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1033\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py:140\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py:250\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    249\u001b[0m         \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    252\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_optimization\u001b[38;5;241m.\u001b[39mrun(kwargs)\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:190\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m         closure()\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:268\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_ready()\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:157\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 157\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    160\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/pytorch_lightning/core/module.py:1303\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimizer_step\u001b[39m(\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1266\u001b[0m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1269\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1270\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1272\u001b[0m \u001b[38;5;124;03m    the optimizer.\u001b[39;00m\n\u001b[1;32m   1273\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1301\u001b[0m \n\u001b[1;32m   1302\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1303\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py:152\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py:239\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py:122\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/torch/optim/adam.py:146\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 146\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    149\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py:108\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_closure\u001b[39m(\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     97\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     98\u001b[0m     optimizer: Optimizer,\n\u001b[1;32m     99\u001b[0m     closure: Callable[[], Any],\n\u001b[1;32m    100\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    hook is called.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m \n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m closure_result\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:144\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:129\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39menable_grad()\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 129\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarning_cache\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:318\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# manually capture logged metrics\u001b[39;00m\n\u001b[0;32m--> 318\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_result_cls\u001b[38;5;241m.\u001b[39mfrom_training_step_output(training_step_output, trainer\u001b[38;5;241m.\u001b[39maccumulate_grad_batches)\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 309\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/.conda/envs/sheaf/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py:391\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 25\u001b[0m, in \u001b[0;36mGCN_module.training_step\u001b[0;34m(self, train_batch, batch_idx)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_batch, batch_idx):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(train_batch)\n\u001b[0;32m---> 25\u001b[0m     x, edge_index, y, train_mask, val_mask \u001b[38;5;241m=\u001b[39m train_batch\n\u001b[1;32m     26\u001b[0m     x, edge_index, y \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m0\u001b[39m], edge_index[\u001b[38;5;241m0\u001b[39m], y[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     27\u001b[0m     train_mask, val_mask \u001b[38;5;241m=\u001b[39m train_mask[\u001b[38;5;241m0\u001b[39m], val_mask[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 5)"
     ]
    }
   ],
   "source": [
    "module = GCN_module().to(device)\n",
    "\n",
    "trainer.fit(module, loader, loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d07994",
   "metadata": {},
   "source": [
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2695b1-50ad-4734-823b-b454f0fcf663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f16e4e-e571-416b-a005-01ef36c5bfec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d836d5e-b5fe-4515-9d7f-b34bf14577aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888ed1dc-5351-42a2-a930-499f6c6524fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cbf60b-02e9-430a-a92a-fbe048bfd4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a03723-e5b3-4454-af90-7ef6d3ead60d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e6910a-677d-4f80-9050-f37ac24f3f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e905182-5e0f-49f8-897a-e5ef6bd16ddd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45446790-efdc-4d5f-a8f7-2bb4dec53310",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj, features, labels, idx_train, idx_val, idx_test = load_data('pygcn/data/cora/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725648ee-ef5a-456e-9d8b-9bb2d2aaa88d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hidden = 16\n",
    "dropout = 0.5\n",
    "lr = 0.01\n",
    "weight_decay = 5e-4\n",
    "device = \"cpu\"\n",
    "\n",
    "model = GCN(nfeat=features.shape[1],\n",
    "            nhid=hidden,\n",
    "            nclass=labels.max().item() + 1,\n",
    "            dropout=dropout)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "model.to(device)\n",
    "features = features.to(device)\n",
    "adj = adj.to(device)\n",
    "labels = labels.to(device)\n",
    "idx_train = idx_train.to(device)\n",
    "idx_val = idx_val.to(device)\n",
    "idx_test = idx_test.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b408014-0ef5-4b24-ace5-3f5529b7474e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(features, adj)\n",
    "    loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
    "    # log\n",
    "    # writer.add_scalar(\"Loss/train\", loss_train, epoch)\n",
    "    acc_train = accuracy(output[idx_train], labels[idx_train])\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # if not args.fastmode:\n",
    "    #     # Evaluate validation set performance separately,\n",
    "    #     # deactivates dropout during validation run.\n",
    "    #     model.eval()\n",
    "    #     output = model(features, adj)\n",
    "\n",
    "    loss_val = F.nll_loss(output[idx_val], labels[idx_val])\n",
    "    acc_val = accuracy(output[idx_val], labels[idx_val])\n",
    "    print('Epoch: {:04d}'.format(epoch+1),\n",
    "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "          'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "          'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "          'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    output = model(features, adj)\n",
    "    loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
    "    acc_test = accuracy(output[idx_test], labels[idx_test])\n",
    "    print(\"Test set results:\",\n",
    "          \"loss= {:.4f}\".format(loss_test.item()),\n",
    "          \"accuracy= {:.4f}\".format(acc_test.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b364f52-6e9a-4821-b7c7-19635d989741",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "\n",
    "t_total = time.time()\n",
    "for epoch in range(epochs):\n",
    "    train(epoch)\n",
    "    \n",
    "writer.flush()\n",
    "\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b3e335-e3c8-4a6c-ab3e-332aa2abbde7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32a969e-0981-4ae5-b29c-75ceadcaab92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cc4139-767a-4435-9a65-fd50019190a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed668cf-0a04-4f6c-a7e8-ec415f229a29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cdb4a3-91f5-46f7-997c-6e7990cc4e60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sheaf",
   "language": "python",
   "name": "sheaf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
